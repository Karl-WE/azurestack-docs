<!doctype html>
<html itemscope itemtype="http://schema.org/WebPage" lang="en" class="no-js">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.103.1" />
<meta name="robots" content="index, follow">


<link rel="shortcut icon" href="/csm-docs/favicons/favicon.ico" >
<link rel="apple-touch-icon" href="/csm-docs/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="icon" type="image/png" href="/csm-docs/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/csm-docs/favicons/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/csm-docs/favicons/android-36x36.png" sizes="36x36">
<link rel="icon" type="image/png" href="/csm-docs/favicons/android-48x48.png" sizes="48x48">
<link rel="icon" type="image/png" href="/csm-docs/favicons/android-72x72.png" sizes="72x72">
<link rel="icon" type="image/png" href="/csm-docs/favicons/android-96x96.png" sizes="96x96">
<link rel="icon" type="image/png" href="/csm-docs/favicons/android-144x144.png" sizes="144x144">
<link rel="icon" type="image/png" href="/csm-docs/favicons/android-192x192.png" sizes="192x192">

<title>PowerStore | Dell Technologies</title>
<meta name="description" content="Code features for PowerStore Driver">
<meta property="og:title" content="PowerStore" />
<meta property="og:description" content="Code features for PowerStore Driver" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://dell.github.io/csm-docs/v2/csidriver/features/powerstore/" /><meta property="article:section" content="v2" />

<meta property="article:modified_time" content="2022-06-22T16:36:23+05:30" /><meta property="og:site_name" content="Dell Technologies" />

<meta itemprop="name" content="PowerStore">
<meta itemprop="description" content="Code features for PowerStore Driver">
<meta itemprop="dateModified" content="2022-06-22T16:36:23+05:30" />
<meta itemprop="wordCount" content="3519">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="PowerStore"/>
<meta name="twitter:description" content="Code features for PowerStore Driver"/>




<link rel="preload" href="/csm-docs/scss/main.min.d0bfa16d819c9dab58324fe79e0fe1241c505038028e706c280c6fb590220afe.css" as="style">
<link href="/csm-docs/scss/main.min.d0bfa16d819c9dab58324fe79e0fe1241c505038028e706c280c6fb590220afe.css" rel="stylesheet" integrity="">

<script
  src="https://code.jquery.com/jquery-3.6.0.min.js"
  integrity="sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK"
  crossorigin="anonymous"></script>
<script defer
  src="https://unpkg.com/lunr@2.3.9/lunr.min.js"
  integrity="sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli"
  crossorigin="anonymous"></script>
<link rel="stylesheet" href="/css/prism.css"/>

  </head>
  <body class="td-page">
    <header>
      
<nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar">
        <a class="navbar-brand" href="/csm-docs/">
		<span class="navbar-logo"><svg id="Layer_1" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1017 132"><defs><style>.cls-1{fill:#fff}</style></defs><title>DellTech_Logo_Prm_Wht_rgb</title><path class="cls-1" d="M1015 84.89c0-12.23-6.8-17.66-20.39-20.38s-21.73-4.08-21.73-13.58c0-6.8 5.44-10.87 15-10.87 12.22.0 16.3 5.43 16.3 12.22l1.36 1.36h5.43l1.37-1.36c0-13.58-10.88-19-24.46-19-15 0-23.1 8.15-23.1 17.67.0 10.86 8.15 16.3 21.73 19s20.38 4.08 20.38 15c0 6.79-4.07 12.23-17.66 12.23-12.22.0-17.66-6.8-17.66-15l-1.35-1.36h-5.44l-1.35 1.36c0 12.23 9.5 21.74 25.8 21.74 17.66.0 25.82-8.15 25.82-19M956.58 71.31l1.36-1.37V65.87c0-19-10.87-32.61-29.89-32.61s-29.89 13.59-29.89 32.61v2.72c0 19 9.51 35.32 31.25 35.32 19 0 25.81-12.23 27.17-20.38l-1.36-1.36h-5.43l-1.36 1.36c-2.72 8.15-8.16 13.59-19 13.59-17.66.0-23.1-16.31-23.1-24.46l1.36-1.35zm-8.15-6.8H907.67l-1.36-1.36c0-9.51 5.44-23.09 21.74-23.09s21.74 13.58 21.74 23.09zm-59.78 36.68V36l-1.36-1.35h-5.43L880.5 36v65.22l1.36 1.36h5.43zm0-78.8V14.24l-1.36-1.36h-5.43l-1.36 1.36v8.15l1.36 1.36h5.43zM837 97.12c-13.59.0-21.74-9.52-21.74-28.53S823.44 40.06 837 40.06s21.73 9.5 21.73 28.53S850.61 97.12 837 97.12M858.76 93c0 17.66-4.07 31.25-20.38 31.25-12.22.0-16.3-5.44-17.66-12.23l-1.35-1.36h-5.44l-1.36 1.36c1.36 10.87 9.51 19 25.81 19 17.67.0 28.53-10.87 28.53-38V36l-1.35-1.35h-4.08L860.12 36l-1.36 8.16H857.4c-2.71-5.43-9.5-10.87-21.74-10.87-19 0-28.53 15-28.53 35.33s9.52 35.32 28.53 35.32c12.24.0 19-5.43 21.74-10.87zm-88.3-53c13.58.0 23.09 10.87 23.09 28.53S784 97.12 770.46 97.12s-23.1-10.87-23.1-28.53 9.51-28.53 23.1-28.53m0 63.85c17.66.0 31.25-12.23 31.25-35.32s-13.59-35.33-31.25-35.33-31.25 12.23-31.25 35.33 13.59 35.32 31.25 35.32m-40.76-2.72V8.81l-1.36-1.36h-5.43l-1.36 1.36v92.38l1.36 1.36h5.43zM680.8 40.06c13.58.0 23.09 10.87 23.09 28.53s-9.51 28.53-23.09 28.53-23.1-10.87-23.1-28.53 9.51-28.53 23.1-28.53m0 63.85c17.66.0 31.25-12.23 31.25-35.32S698.46 33.26 680.8 33.26s-31.25 12.23-31.25 35.33 13.59 35.32 31.25 35.32m-39.4-2.72V60.43c0-17.66-9.51-27.17-24.45-27.17-9.52.0-17.67 4.08-21.74 10.87h-1.36L592.49 36l-1.36-1.35h-4.08L585.7 36v65.22l1.35 1.36h5.44l1.36-1.36V64.51c0-15 6.79-24.45 21.73-24.45 10.87.0 17.66 6.79 17.66 20.37v40.76l1.37 1.36H640zm-69.29.0V60.43c0-17.66-9.51-27.17-24.45-27.17-9.52.0-17.66 4.08-21.74 10.87h-1.36V8.81L523.2 7.45h-5.43l-1.36 1.36v92.38l1.36 1.36h5.43l1.36-1.36V64.51c0-15 6.8-24.45 21.74-24.45 10.87.0 17.66 6.79 17.66 20.37v40.76l1.36 1.36h5.44zM455.28 68.59c0-19 9.5-28.53 23.09-28.53s19 8.15 20.38 16.29l1.35 1.37h5.44l1.36-1.37c-1.36-13.58-12.23-23.09-28.53-23.09-17.66.0-31.24 10.87-31.24 35.33s13.58 35.32 31.24 35.32c16.3.0 27.17-9.51 28.53-23.1l-1.36-1.36H500.1l-1.35 1.36C497.39 89 492 97.12 478.37 97.12s-23.09-9.52-23.09-28.53m-14.95 2.72 1.36-1.37V65.87c0-19-10.87-32.61-29.9-32.61s-29.88 13.59-29.88 32.61v2.72c0 19 9.51 35.32 31.25 35.32 19 0 25.81-12.23 27.17-20.38L439 82.17h-5.43l-1.36 1.36c-2.72 8.15-8.15 13.59-19 13.59-17.66.0-23.1-16.31-23.1-24.46l1.36-1.35zm-8.15-6.8H391.42l-1.36-1.36c0-9.51 5.44-23.09 21.73-23.09s21.75 13.58 21.75 23.09zM395.57 12.88V8.81l-1.36-1.36H323.56L322.2 8.81v4.07l1.36 1.36h29.89l1.36 1.36v85.59l1.36 1.36h5.43l1.36-1.36V15.6l1.36-1.36h29.89z"/><path class="cls-1" d="M322.2 83.65v18.9H260.85V7.45h21.6v76.2zM38.55 102.55A47.57 47.57.0 0084.58 67l53.8 42 53.77-42v35.56H253.5V83.65H213.75V7.45h-21.6V43L140.58 83.3l-11.54-9L153.73 55l26.89-21-15.35-12-51.58 40.3-11.53-9L153.73 13 138.38 1 84.58 43a47.57 47.57.0 00-46-35.58H0v95.1zM21.6 83.65V26.35H38.55c14.33.0 26 12.83 26 28.65s-11.67 28.65-26 28.65z"/></svg></span><span class="font-weight-bold">Dell Technologies</span>
	</a>
	<div class="td-navbar-nav-scroll ml-md-auto" id="main_navbar">
		<ul class="navbar-nav mt-2 mt-lg-0">
			
			
			<li class="nav-item mr-4 mb-2 mb-lg-0">
				
				
				
				
				
				
				
				
				<a class="nav-link" href="/csm-docs/docs/" ><span>Dell Technologies (Dell) Container Storage Modules (CSM)</span></a>
			</li>
			
			<li class="nav-item mr-4 mb-2 mb-lg-0">
				
				
				
				
				
				
				<a class="nav-link" href="https://github.com/dell/csm" target="_blank" ><span>GitHub</span></a>
			</li>
			
			
			<li class="nav-item dropdown mr-4 d-none d-lg-block">
				<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
	Releases
</a>
<div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
	
	
	
	<a class="dropdown-item" href="https://dell.github.io/csm-docs/docs/">Current(v1.3)</a>
	
	<a class="dropdown-item" href="https://dell.github.io/csm-docs/v1">v1.2.1</a>
	
	<a class="dropdown-item" href="https://dell.github.io/csm-docs/v2">v1.2</a>
	
	<a class="dropdown-item" href="https://dell.github.io/csm-docs/v3">v1.1</a>
	
</div>

			</li>
			
			
		</ul>
	</div>
	<div class="navbar-nav d-none d-lg-block"><input
  type="search"
  class="form-control td-search-input"
  placeholder="&#xf002; Search this site…"
  aria-label="Search this site…"
  autocomplete="off"
  
  data-offline-search-index-json-src="/csm-docs/offline-search-index.1e79a0908736ce645e100ec566b3c5a3.json"
  data-offline-search-base-href="/"
  data-offline-search-max-results="10"
>
</div>
</nav>

    </header>
    <div class="container-fluid td-default td-outer">
      <main role="main" class="td-main">
        

<h2 id="creating-volumes-and-consuming-them">Creating volumes and consuming them</h2>
<p>Create a file <code>simple.yaml</code> using sample yaml files located at tests/simple/</p>
<p>This command creates a statefulset that consumes three volumes of default storage classes</p>
<pre><code class="language-bash">kubectl create -f tests/simple/simple.yaml
</code></pre>
<p>After executing this command 3 PVC and statefulset are created in the <code>testpowerstore</code> namespace.
You can check created PVCs by running <code>kubectl get pvc -n testpowerstore</code> and check statefulset&rsquo;s pods by running <code>kubectl get pods -n testpowerstore</code></p>
<p>The pod must be <code>Ready</code> and <code>Running</code></p>
<blockquote>
<p>If Pod is in CrashLoopback or PVCs is in a Pending state then driver installation is not successful, check logs of node and controller.</p>
</blockquote>
<h2 id="deleting-volumes">Deleting volumes</h2>
<p>To delete volumes, pod and statefulset run, use the command:</p>
<pre><code class="language-bash">kubectl delete -f tests/simple/simple.yaml
</code></pre>
<h2 id="consuming-existing-volumes-with-static-provisioning">Consuming existing volumes with static provisioning</h2>
<p>You can use existent volumes from PowerStore array as Persistent Volumes in your Kubernetes, perform the following steps:</p>
<ol>
<li>Open your volume in PowerStore Management UI, and take a note of volume-id. The volume link must look similar to <code>https://&lt;powerstore.api.ip&gt;/#/storage/volumes/0055558c-5ae1-4ed1-b421-6f5a9475c19f/capacity</code>, where the <code>volume-id</code> is <code>0055558c-5ae1-4ed1-b421-6f5a9475c19f</code>.</li>
<li>Create PersistentVolume and use this volume-id in volumeHandle in format &lt;volume-id/globalID/protocol&gt; in the manifest. Modify other parameters according to your needs.</li>
</ol>
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolume
metadata:
    name: existingvol
spec:
    accessModes:
      - ReadWriteOnce
    capacity:
        storage: 30Gi
    csi:
        driver: csi-powerstore.dellemc.com
        volumeHandle: 0055558c-5ae1-4ed1-b421-6f5a9475c19f/unique/scsi
    persistentVolumeReclaimPolicy: Retain
    storageClassName: powerstore
    volumeMode: Filesystem
</code></pre>
<ol start="3">
<li>Create PersistentVolumeClaim to use this PersistentVolume.</li>
</ol>
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
    name: pvol
spec:
    accessModes:
      - ReadWriteOnce
    volumeMode: Filesystem
    resources:
        requests:
            storage: 30Gi
    storageClassName: powerstore
</code></pre>
<ol start="4">
<li>Then use this PVC as a volume in a pod.</li>
</ol>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
    name: static-prov-pod
spec:
    containers:
      - name: test
        image: quay.io/centos/centos:latest
        command: [ &quot;/bin/sleep&quot;, &quot;3600&quot; ]
        volumeMounts:
          - mountPath: &quot;/data0&quot;
            name: pvol
    volumes:
      - name: pvol
        persistentVolumeClaim:
            claimName: pvol
</code></pre>
<ol start="5">
<li>After the pod is <code>Ready</code> and <code>Running</code>, you can start to use this pod and volume.</li>
</ol>
<h2 id="volume-snapshot-feature">Volume Snapshot Feature</h2>
<p>The CSI PowerStore driver version 2.0.0 and higher supports v1 snapshots.</p>
<p>In order to use Volume Snapshots, ensure the following components have been deployed to your cluster:</p>
<ul>
<li>Kubernetes Volume Snapshot CRDs</li>
<li>Volume Snapshot Controller</li>
<li>Volume Snapshot Class</li>
</ul>
<blockquote>
<p>Note: From v1.4, the CSI PowerStore driver installation process will no longer create VolumeSnapshotClass. 
If you want to create VolumeSnapshots, then create a VolumeSnapshotClass using the sample provided in the <em>samples</em> folder</p>
</blockquote>
<h3 id="creating-volume-snapshots">Creating Volume Snapshots</h3>
<p>The following is a sample manifest for creating a Volume Snapshot using the <strong>v1</strong> snapshot APIs:</p>
<pre><code class="language-yaml">apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: pvol0-snap1
spec:
  volumeSnapshotClassName: powerstore-snapclass
  source:
    persistentVolumeClaimName: pvol0

</code></pre>
<p>After the VolumeSnapshot has been successfully created by the CSI PowerStore driver, a VolumeSnapshotContent object is automatically created. When the status of the VolumeSnapshot object has the <em>readyToUse</em> field set to <em>true</em>, it is available for use.</p>
<p>The following is the relevant section of VolumeSnapshot object status:</p>
<pre><code class="language-yaml">status:
  boundVolumeSnapshotContentName: snapcontent-5a8334d2-eb40-4917-83a2-98f238c4bda
  creationTime: &quot;2020-07-16T08:42:12Z&quot;
  readyToUse: true
</code></pre>
<h3 id="snapshot-feature-is-optional-for-the-installation">Snapshot feature is optional for the installation</h3>
<p>CSI PowerStore driver version 1.4 makes the snapshot feature optional for the installation.</p>
<p>To enable or disable this feature, change values.snapshot.enable parameter to true or false, specify the following in <code>values.yaml</code> to enable this feature</p>
<pre><code class="language-yaml">snapshot:
  enable: true
</code></pre>
<p>External Snapshotter and its CRDs are not installed even if the Snapshot feature is enabled. These have to be installed manually before the installation.</p>
<p>Disabling the Snapshot feature will opt out of the snapshotter sidecar from the installation.</p>
<h3 id="creating-pvcs-with-volume-snapshots-as-source">Creating PVCs with Volume Snapshots as Source</h3>
<p>The following is a sample manifest for creating a PVC with a VolumeSnapshot as a source:</p>
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: restorepvc
  namespace: testpowerstore
spec:
  storageClassName: powerstore
  dataSource:
    name: pvol0-snap
    kind: VolumeSnapshot
    apiGroup: snapshot.storage.k8s.io
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 8Gi
</code></pre>
<h2 id="iscsi-chap">iSCSI CHAP</h2>
<p>The CSI PowerStore driver Version 1.3.0 and later extends Challenge Handshake Authentication Protocol (CHAP) support by adding automatic credentials generation.</p>
<p>This means that you no longer need to provide chapsecret/chapuser credentials, they will be automatically generated by the driver for each host.</p>
<p>To enable this feature you need to set <code>connection.enableCHAP</code> to <code>true</code> when installing with <strong>helm</strong> or set <code>X_CSI_POWERSTORE_ENABLE_CHAP</code> to <code>true</code> in your PowerStore CustomResource when installing using <strong>operator</strong>.</p>
<p>The driver uses the generated chapsecret to configure the iSCSI node database on each node with iSCSI access.</p>
<p>When creating a new host on powerstore array driver will populate host chap credentials with generated values. When re-using already existing hosts driver must override existing CHAP credentials with newly generated ones.</p>
<h2 id="volume-expansion">Volume Expansion</h2>
<p>The CSI PowerStore driver version 1.1 and later supports the expansion of Persistent Volumes (PVs). This expansion can be done either online (for example, when a PV is attached to a node) or offline (for example, when a PV is not attached to any node).</p>
<p>To use this feature, the storage class that is used to create the PV must have the attribute <code>allowVolumeExpansion</code> set to true.</p>
<p>The following is a sample manifest for a storage class that allows for Volume Expansion:</p>
<pre><code class="language-yaml">apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
    name: powerstore-expand-sc
    annotations:
        storageclass.kubernetes.io/is-default-class: false
provisioner: csi-powerstore.dellemc.com
reclaimPolicy: Delete
allowVolumeExpansion: true # Set this attribute to true if you plan to expand any PVCs created using this storage class
parameters:
    FsType: xfs
</code></pre>
<p>To resize a PVC, edit the existing PVC spec and set spec.resources.requests.storage to the intended size. For example, if you have a PVC pstore-pvc-demo of size 3Gi, then you can resize it to 30Gi by updating the PVC.</p>
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
    name: pstore-pvc-demo
    namespace: test
spec:
    accessModes:
      - ReadWriteOnce
    volumeMode: Filesystem
    resources:
        requests:
            storage: 30Gi # Updated size from 3Gi to 30Gi
    storageClassName: powerstore-expand-sc
</code></pre>
<blockquote>
<p>The Kubernetes Volume Expansion feature can only be used to increase the size of a volume. It cannot be used to shrink a volume.</p>
</blockquote>
<h2 id="raw-block-support">Raw block support</h2>
<p>CSI PowerStore driver supports managing Raw Block volumes since version 1.1</p>
<p>Raw Block volumes are created using the volumeDevices list in the pod template spec with each entry accessing a
<code>volumeClaimTemplate</code> specifying a <code>volumeMode: Block</code>. An example configuration is outlined here:</p>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: StatefulSet
metadata:
    name: powerstoretest
    namespace: {{ .Values.namespace }}
spec:
    ...
        spec:
            ...
            containers:
              - name: test
                ...
                volumeDevices:
                  - devicePath: &quot;/dev/data0&quot;
                    name: pvol
    volumeClaimTemplates:
      - metadata:
            name: pvol
        spec:
        accessModes:
          - ReadWriteOnce
        volumeMode: Block
        storageClassName: powerstore
        resources:
            requests:
                storage: 8Gi
</code></pre>
<p>Allowable access modes are <code>ReadWriteOnce</code>, <code>ReadWriteMany</code>, and for block devices that have been previously initialized,
<code>ReadOnlyMany</code>.</p>
<p>Raw Block volumes are presented as a block device to the pod by using a bind mount to a block device in the node&rsquo;s file system.
The driver does not format or check the format of any file system on the block device. Raw Block volumes do support online
Volume Expansion, but it is up to the application to manage to reconfigure the file system (if any) to the new size.</p>
<p>For additional information, see the <a href="https://kubernetes.io/DOCS/CONCEPTS/STORAGE/PERSISTENT-VOLUMES/#raw-block-volume-support">kubernetes</a> website.</p>
<h2 id="volume-cloning-feature">Volume Cloning Feature</h2>
<p>The CSI PowerStore driver version 1.1 and later supports volume cloning. This allows specifying existing PVCs in the <em>dataSource</em> field to indicate a user would like to clone a Volume.</p>
<p>Source and destination PVC must be in the same namespace and have the same Storage Class.</p>
<p>To clone a volume, you must first have an existing pvc, for example, pvol0:</p>
<pre><code class="language-yaml">kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: pvol0
  namespace: testpowerstore
spec:
  storageClassName: powerstore
  accessModes:
  - ReadWriteOnce
  volumeMode: Filesystem
  resources:
    requests:
      storage: 8Gi
</code></pre>
<p>The following is a sample manifest for cloning pvol0:</p>
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: clonedpvc
  namespace: testpowerstore
spec:
  storageClassName: powerstore
  dataSource:
    name: pvol0
    kind: PersistentVolumeClaim
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 8Gi
</code></pre>
<h2 id="ephemeral-inline-volume">Ephemeral Inline Volume</h2>
<p>The CSI PowerStore driver version 1.2 and later supports ephemeral inline CSI volumes. This feature allows CSI volumes to be specified directly in the pod specification.</p>
<p>At runtime, nested inline volumes follow the ephemeral lifecycle of their associated pods where the driver handles all phases of volume operations as pods are created and destroyed.</p>
<p>The following is a sample manifest for creating ephemeral volume in pod manifest with CSI PowerStore driver.</p>
<pre><code class="language-yaml">kind: Pod
apiVersion: v1
metadata:
  name: powerstore-inline-volume
spec:
  containers:
    - name: test-container
      image: quay.io/centos/centos
      command: [ &quot;sleep&quot;, &quot;3600&quot; ]
      volumeMounts:
      - mountPath: &quot;/data&quot;
        name: volume
  volumes:
  - name: volume
    csi:
      driver: csi-powerstore.dellemc.com
      fsType: &quot;ext4&quot;
      volumeAttributes:
        size: &quot;20Gi&quot;
        arrayID: &quot;unique&quot;
</code></pre>
<p>This manifest creates a pod and attaches a newly created ephemeral inline CSI volume to it.</p>
<p>To create <code>NFS</code> volume you need to provide <code>nasName:</code> parameters that point to the name of your NAS Server in pod manifest like so</p>
<pre><code class="language-yaml">  volumes:
  - name: volume
    csi:
      driver: csi-powerstore.dellemc.com
      fsType: &quot;nfs&quot;
      volumeAttributes:
        size: &quot;20Gi&quot;
        nasName: &quot;csi-nas-name&quot;
        nfsAcls: &quot;0777&quot;
</code></pre>
<h2 id="controller-ha">Controller HA</h2>
<p>The CSI PowerStore driver version 1.2 and later introduces the controller HA feature. Instead of StatefulSet, controller pods are deployed as a Deployment.</p>
<p>By default number of replicas is set to 2, you can set <code>controller.replicas</code> parameter to 1 in <code>my-powerstore-settings.yaml</code> if you want to disable controller HA for your installation. When installing via Operator you can change <code>replicas</code> parameter in <code>spec.driver</code> section in your PowerStore Custom Resource.</p>
<p>When multiple replicas of controller pods are in the cluster, each sidecar (attacher, provisioner, resizer, snapshotter) tries to get a lease so only one instance of each sidecar would be active in the cluster at a time.</p>
<h3 id="driver-pod-placement">Driver pod placement</h3>
<p>You can configure where driver controller and worker pods must be placed. 
To configure use <code>nodeSelector</code> and <code>tolerations</code> mechanisms you can configure in your <code>my-powerstore-settings.yaml</code></p>
<p>For example, you can specify <code>tolerations</code> to assign driver controller pods on controller nodes too:</p>
<pre><code class="language-yaml"># &quot;controller&quot; allows to configure controller specific parameters
controller:
  # &quot;controller.nodeSelector&quot; defines what nodes would be selected for pods of controller deployment
  nodeSelector:

# &quot;controller.tolerations&quot; defines tolerations that would be applied to controller deployment
  tolerations:
   - key: &quot;node-role.kubernetes.io/master&quot;
     operator: &quot;Exists&quot;
     effect: &quot;NoSchedule&quot;
</code></pre>
<p>If you want to assign controller pods ONLY on controller nodes you need to configure <code>nodeSelector</code>:</p>
<pre><code class="language-yaml"># &quot;controller&quot; allows to configure controller specific parameters
controller:
  # &quot;controller.nodeSelector&quot; defines what nodes would be selected for pods of controller deployment
  nodeSelector:
    node-role.kubernetes.io/master: &quot;&quot;

  # &quot;controller.tolerations&quot; defines tolerations that would be applied to controller deployment
  tolerations:
   - key: &quot;node-role.kubernetes.io/master&quot;
     operator: &quot;Exists&quot;
     effect: &quot;NoSchedule&quot;
</code></pre>
<p>As mentioned earlier, you can configure where node driver pods would be assigned in the similar way in <code>node</code> section of <code>my-powerstore-settings.yaml</code></p>
<h2 id="topology">Topology</h2>
<p>The CSI PowerStore driver version 1.2 and later supports Topology which forces volumes to be placed on worker nodes that have connectivity to the backend storage. This covers use cases where users have chosen to restrict the nodes on which the CSI driver is deployed.</p>
<p>This Topology support does not include customer-defined topology, users cannot create their own labels for nodes, they must use whatever labels are returned by the driver and applied automatically by Kubernetes on its nodes.</p>
<h3 id="topology-usage">Topology Usage</h3>
<p>To use the Topology features user must create their own storage classes similar to those that can be found in <code>samples/storageclass</code> folder.</p>
<p>The following is one of example storage class manifest:</p>
<pre><code class="language-yaml">apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: powerstore-fc
provisioner: csi-powerstore.dellemc.com
reclaimPolicy: Delete
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer
allowedTopologies:
  - matchLabelExpressions:
      - key: csi-powerstore.dellemc.com/127.0.0.1-fc
        values:
          - &quot;true&quot;
</code></pre>
<p>This example matches all nodes where the driver has a connection to PowerStore with an IP of <code>127.0.0.1</code> via FibreChannel. Similar examples can be found in mentioned folder for NFS, iSCSI and NVMe.</p>
<p>You can check what labels your nodes contain by running <code>kubectl get nodes --show-labels</code></p>
<blockquote>
<p>Notice that <code>volumeBindingMode:</code> is set to <code>WaitForFirstConsumer</code> this is required for the topology feature to work.</p>
</blockquote>
<p>For any additional information about the topology, see the <a href="https://kubernetes-csi.github.io/docs/topology.html">Kubernetes Topology documentation</a>.</p>
<h2 id="reuse-powerstore-hostname">Reuse PowerStore hostname</h2>
<p>The CSI PowerStore driver version 1.2 and later can automatically detect if the current node was already registered as a Host on the storage array before. It will check if Host initiators and node initiators (FC, iSCSI or NVMe) match. If they do, the driver will not create a new host and will take the existing name of the Host as nodeID.</p>
<h2 id="multiarray-support">Multiarray support</h2>
<p>The CSI PowerStore driver version 1.3.0 and later support managing multiple PowerStore arrays from the single driver instance. This feature is enabled by default and integrated to even single instance installations.</p>
<p>To manage multiple arrays you need to create an array connection configuration that lists multiple arrays.</p>
<h3 id="creating-array-configuration">Creating array configuration</h3>
<p>Create a file called <code>config.yaml</code> and populate it with the following content</p>
<pre><code class="language-yaml">   arrays:
      - endpoint: &quot;https://10.0.0.1/api/rest&quot;     # full URL path to the PowerStore API
        globalID: &quot;unique&quot;                        # global ID to identify array
        username: &quot;user&quot;                          # username for connecting to API
        password: &quot;password&quot;                      # password for connecting to API
        skipCertificateValidation: true                            # use insecure connection or not
        default: true                             # treat current array as a default (would be used by storage classes without arrayIP parameter)
        blockProtocol: &quot;ISCSI&quot;                    # what transport protocol use on node side (FC, ISCSI, NVMeTCP, None, or auto)
        nasName: &quot;nas-server&quot;                     # what NAS must be used for NFS volumes
        nfsAcls: &quot;0777&quot;                           # (Optional) defines permissions - POSIX mode bits or NFSv4 ACLs, to be set on NFS target mount directory.
                                                  # NFSv4 ACls are supported for NFSv4 shares on NFSv4 enabled NAS servers only. POSIX ACLs are not supported and only POSIX mode bits are supported for NFSv3 shares.
      - endpoint: &quot;https://10.0.0.2/api/rest&quot;
        globalID: &quot;unique&quot; 
        username: &quot;user&quot;                          
        password: &quot;password&quot;
        skipCertificateValidation: true                           
        blockProtocol: &quot;FC&quot;                    
</code></pre>
<p>Here we specify that we want to CSI driver to manage two arrays: one with an IP <code>10.0.0.1</code> and the other with an IP <code>10.0.0.2</code>, we want to connect to the first array with <code>iSCSI</code> protocol and with <code>FC</code> to the second array. Also, we want to be able to create NFS-based volume so we provide the name of the NAS to the first array.</p>
<p>To use this config we need to create a Kubernetes secret from it, to do so create a file called <code>secret.yaml</code> in the same folder and populate it with the following content:</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: powerstore-config
  namespace: &lt;driver-namespace&gt;
type: Opaque
data:
  config: CONFIG_YAML
</code></pre>
<p>Apply the secret by running following command:</p>
<pre><code class="language-bash">sed &quot;s/CONFIG_YAML/`cat config.yaml | base64 -w0`/g&quot; secret.yaml | kubectl apply -f -
</code></pre>
<h3 id="creating-storage-classes">Creating storage classes</h3>
<p>To be able to provision Kubernetes volumes using a specific array we need to create corresponding storage classes.</p>
<p>Create file <code>storageclass.yaml</code> and populate it with the following content:</p>
<pre><code class="language-yaml">apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: powerstore-1
provisioner: csi-powerstore.dellemc.com
reclaimPolicy: Delete
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer
parameters:
  arrayID: &quot;GlobalUniqueID&quot;
  FsType: &quot;ext4&quot;
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: powerstore-2
provisioner: csi-powerstore.dellemc.com
reclaimPolicy: Delete
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer
parameters:
  arrayID: &quot;GlobalUniqueID&quot;
  FsType: &quot;xfs&quot;
</code></pre>
<p>Here we specify two storage classes: one of them uses the first array and <code>ext4</code> filesystem, and the other uses the second array and <code>xfs</code> filesystem.</p>
<p>Then we need to apply storage classes to Kubernetes using <code>kubectl</code>:</p>
<pre><code class="language-bash">kubectl create -f storageclass.yaml
</code></pre>
<p>After that, you can use <code>powerstore-1</code> storage class to create volumes on the first array and <code>powerstore-2</code> storage class to create volumes on the second array.</p>
<h2 id="dynamic-secret-change-detection">Dynamic secret change detection</h2>
<p>CSI PowerStore driver version 1.3.0 and later supports the ability to detect changes to array configuration Kubernetes secret. This essentially means that you can change credentials for your PowerStore arrays in-flight (without restarting the driver).</p>
<p>To do so just change your configuration file <code>config.yaml</code> and apply it again using the following command:</p>
<pre><code class="language-bash">sed &quot;s/CONFIG_YAML/`cat config.yaml | base64 -w0`/g&quot; secret.yaml | kubectl apply -f -
</code></pre>
<p>After Kubernetes remounts secret to driver containers (this usually takes around one minute), a driver must detect the change and start using this new configuration information.</p>
<h2 id="configuring-custom-access-to-nfs-exports">Configuring custom access to NFS exports</h2>
<p>CSI PowerStore driver Version 1.3.0 and later supports the ability to configure NFS access to nodes that use dedicated storage networks.</p>
<p>To enable this feature you need to specify <code>externalAccess</code> parameter in your helm <code>values.yaml</code> file or <code>X_CSI_POWERSTORE_EXTERNAL_ACCESS</code> variable when creating CustomResource using an operator.</p>
<p>The value of that parameter is added as an additional entry to NFS Export host access.</p>
<p>For example the following notation:</p>
<pre><code class="language-yaml">externalAccess: &quot;10.0.0.0/24&quot;
</code></pre>
<p>This means that we allow for NFS Export created by driver to be consumed by address range <code>10.0.0.0-10.0.0.255</code>.</p>
<h2 id="array-identification-based-on-globalid">Array identification based on GlobalID</h2>
<p>CSI PowerStore driver version 1.4.0 onwards slightly changes the way arrays are being identified in runtime.
In previous versions of the driver, a management IP address was used to identify an array. The address change could lead to an invalid state of PV.
From version 1.4.0 a unique GlobalID string is used for an array identification.
It has to be specified in <code>config.yaml</code> and in Storage Classes.</p>
<p>The change provides backward compatibility with previously created PVs. 
However, to provision new volumes, make sure to delete old Storage Classes and create new ones with <code>arrayID</code> instead of <code>arrayIP</code> specified.</p>
<blockquote>
<p>NOTE: It is recommended to migrate the PVs to new identifiers before changing management IPs of storage systems. The recommended way to do it is to clone the existing volume and delete the old one. The cloned volume will automatically switch to using globalID instead of management IP.</p>
</blockquote>
<h2 id="root-squashing">Root squashing</h2>
<p>CSI PowerStore driver version 1.4.0 and later allows users to enable root squashing for NFS volumes provisioned by the driver.</p>
<p>Root squashing rule prevents root users on NFS clients from exercising root privileges on the NFS server.</p>
<p>To enable this rule, you need to set parameter <code>allowRoot</code> to <code>false</code> in your NFS storage class.</p>
<p>Your storage class definition must look similar to this:</p>
<pre><code class="language-yaml">apiVersion: storage.k8s.io/v1
kind: StorageClass
...
parameters:
  ...
  allowRoot: &quot;false&quot;  # enables or disables root squashing
</code></pre>
<blockquote>
<p>The 1.4 version and later of the driver also enables any container user, to have full access to provisioned NFS volume, in earlier versions only <code>root</code> user had access</p>
</blockquote>
<h2 id="dynamic-logging-configuration">Dynamic Logging Configuration</h2>
<p>This feature is introduced in CSI Driver for PowerStore version 2.0.0.</p>
<h3 id="helm-based-installation">Helm based installation</h3>
<p>As part of driver installation, a ConfigMap with the name <code>powerstore-config-params</code> is created, which contains attributes <code>CSI_LOG_LEVEL</code> which specifies the current log level of CSI driver and <code>CSI_LOG_FORMAT</code> which specifies the current log format of CSI driver.</p>
<p>Users can set the default log level by specifying log level to <code>logLevel</code> and log format to <code>logFormat</code> attribute in <code>my-powerstore-settings.yaml</code> during driver installation.</p>
<p>To change the log level or log format dynamically to a different value user can edit the same values.yaml, and run the following command</p>
<pre><code>cd dell-csi-helm-installer
./csi-install.sh --namespace csi-powerstore --values ./my-powerstore-settings.yaml --upgrade
</code></pre>
<p>Note: here <code>my-powerstore-settings.yaml</code> is a <code>values.yaml</code> file which user has used for driver installation.</p>
<h3 id="operator-based-installation">Operator based installation</h3>
<p>As part of driver installation, a ConfigMap with the name <code>powerstore-config-params</code> is created using the manifest located in the sample file. This ConfigMap contains attributes <code>CSI_LOG_LEVEL</code> which specifies the current log level of the CSI driver and <code>CSI_LOG_FORMAT</code> which specifies the current log format of the CSI driver. To set the default/initial log level user can set this field during driver installation.</p>
<p>To update the log level dynamically user has to edit the ConfigMap <code>powerstore-config-params</code> and update <code>CSI_LOG_LEVEL</code> to the desired log level and <code>CSI_LOG_FORMAT</code> to the desired log format.</p>
<pre><code>kubectl edit configmap -n csi-powerstore powerstore-config-params
</code></pre>
<h2 id="nat-support">NAT Support</h2>
<p>CSI Driver for Dell Powerstore is supported in the NAT environment for NFS protocol.</p>
<p>The user will be able to install the driver and able to create pods.</p>
<h2 id="pvpvc-metrics">PV/PVC Metrics</h2>
<p>CSI Driver for Dell Powerstore 2.1.0 and above supports volume health monitoring. To enable Volume Health Monitoring from the node side, the alpha feature gate CSIVolumeHealth needs to be enabled. To use this feature, set controller.healthMonitor.enabled and node.healthMonitor.enabled to true. To change the monitor interval, set controller.healthMonitor.volumeHealthMonitorInterval parameter.</p>
<h2 id="single-pod-access-mode-for-persistentvolumes">Single Pod Access Mode for PersistentVolumes</h2>
<p>Starting from version 2.1, CSI Driver for Powerstore now supports a new access mode <code>ReadWriteOncePod</code> for PersistentVolumes and PersistentVolumeClaims. With this feature, CSI Driver for Powerstore allows restricting volume access to a single pod in the cluster and within a worker node.</p>
<p>Prerequisites</p>
<ol>
<li>
<p>Enable the ReadWriteOncePod feature gate for kube-apiserver, kube-scheduler, and kubelet as ReadWriteOncePod access mode is in alpha for Kubernetes v1.22 and is supported only for CSI volumes. You can enable the feature by setting command-line argument:
<code>--feature-gates=&quot;...,ReadWriteOncePod=true&quot;</code></p>
</li>
<li>
<p>Create a PVC with access mode set to ReadWriteOncePod like shown in the sample below</p>
</li>
</ol>
<pre><code class="language-yaml">kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: single-node-single-writer
spec:
  accessModes:
  - ReadWriteOncePod # Allow only a single pod to access single-node-single-writer
  resources:
    requests:
      storage: 5Gi
</code></pre>
<blockquote>
<p>Note: The access mode ReadWriteOnce allows multiple pods to access a single volume within a single worker node and the behavior is consistent across all supported Kubernetes versions.</p>
</blockquote>
<h2 id="posix-mode-bits-and-nfsv4-acls">POSIX mode bits and NFSv4 ACLs</h2>
<p>CSI PowerStore driver version 2.2.0 and later allows users to set user-defined permissions on NFS target mount directory using POSIX mode bits or NFSv4 ACLs.</p>
<p>NFSv4 ACLs are supported for NFSv4 shares on NFSv4 enabled NAS servers only. Please ensure the order when providing the NFSv4 ACLs.</p>
<p>To use this feature, provide permissions in <code>nfsAcls</code> parameter in values.yaml, secrets or NFS storage class.</p>
<p>For example:</p>
<ol>
<li>POSIX mode bits</li>
</ol>
<pre><code class="language-yaml">nfsAcls: &quot;0755&quot;
</code></pre>
<ol start="2">
<li>NFSv4 ACLs</li>
</ol>
<pre><code class="language-yaml">nfsAcls: &quot;A::OWNER@:rwatTnNcCy,A::GROUP@:rxtncy,A::EVERYONE@:rxtncy,A::user@domain.com:rxtncy&quot;
</code></pre>
<blockquote>
<p>Note: If no values are specified, default value of &ldquo;0777&rdquo; will be set.
POSIX ACLs are not supported and only POSIX mode bits are supported for NFSv3 shares.</p>
</blockquote>
<h2 id="nvmetcp-support">NVMe/TCP Support</h2>
<p>CSI Driver for Dell Powerstore 2.2.0 and above supports NVMe/TCP provisioning. To enable NVMe/TCP provisioning, blockProtocol on secret should be specified as <code>NVMeTCP</code>. 
In case blockProtocol is specified as <code>auto</code>, the driver will be able to find the initiators on the host and choose the protocol accordingly. If the host has multiple protocols enabled, then FC gets the highest priority followed by iSCSI and then NVMeTCP.</p>
<blockquote>
<p>Note: NVMe/TCP is not supported on RHEL 7.x versions and CoreOS. 
NVMe/TCP is supported with Powerstore 2.1 and above.</p>
</blockquote>



      </main>
      
<footer class="bg-dark py-5 row d-print-none">
  <div class="container-fluid mx-sm-5">
    <div class="row">
      <div class="col-6 col-sm-4 text-xs-center order-sm-2">
        
        
        
      </div>
      <div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="GitHub" aria-label="GitHub">
    <a class="text-white" target="_blank" rel="noopener" href="https://github.com/dell/csm" aria-label="GitHub">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Slack" aria-label="Slack">
    <a class="text-white" target="_blank" rel="noopener" href="http://del.ly/Slack_request" aria-label="Slack">
      <i class="fab fa-slack"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-12 col-sm-4 text-center py-2 order-sm-2">
        <small class="text-white">&copy; 2022 The Dell Technologies All Rights Reserved</small>
        <small class="ml-1"><a href="https://www.dell.com/learn/us/en/uscorp1/policies-privacy" target="_blank" rel="noopener">Privacy Policy</a></small>
	
		
	
      </div>
    </div>
  </div>
</footer>


    </div>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"
    integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN"
    crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js"
    integrity="sha512-UR25UO94eTnCVwjbXozyeVd6ZqpaAE9naiEUBK/A+QDbfSTQFhPGj5lOR6d8tsgbBk84Ggb5A3EkjsOgPRPcKA=="
    crossorigin="anonymous"></script>





<script src='/js/tabpane-persist.js'></script>




















<script src="/csm-docs/js/main.min.9f90c5deff5c6f69d5eaaf614a76a233d8b0b3ae70b942fc78919b6d08041034.js" integrity="sha256-n5DF3v9cb2nV6q9hSnaiM9iws65wuUL8eJGbbQgEEDQ=" crossorigin="anonymous"></script>



<script src='/js/prism.js'></script>



  </body>
</html>